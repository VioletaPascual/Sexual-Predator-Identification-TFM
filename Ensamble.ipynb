{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d613815",
   "metadata": {},
   "source": [
    "# **Sexual Predator Identification Ensamble**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28e5f0",
   "metadata": {},
   "source": [
    "### 0. 1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740516b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 19:12:00.986159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754853121.011664 3094594 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754853121.018771 3094594 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754853121.043728 3094594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754853121.043796 3094594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754853121.043798 3094594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754853121.043801 3094594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-10 19:12:01.059093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a6e2b2-5a80-42f7-b29f-6bf510985a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Excluye la GPU 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afd5bb",
   "metadata": {},
   "source": [
    "### 0.2. Load data. Predator's ID and Chats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f65600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\") as f:\n",
    "    predator_ids_train = set(f.read().splitlines())\n",
    "\n",
    "tree_train = ET.parse(\"pan12-sexual-predator-identification-training-corpus-2012-05-01.xml\")\n",
    "root_train = tree_train.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c7611",
   "metadata": {},
   "source": [
    "### 1. **Filtering stage.**\n",
    "\n",
    "Conversations with only one participant, fewer than six interventions per user or long sequences of unrecognized characters (likely images) were discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81433343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_conversations = 0\n",
    "#discarded_messages = []\n",
    "conversations_clean = []\n",
    "#predators_in_filtered_conversations = set()\n",
    "\n",
    "junk_pattern = re.compile(r\"[^a-zA-Z0-9áéíóúÁÉÍÓÚñÑüÜ\\s.,!?*\\'\\\"@():;<>\\/\\-]+\")\n",
    "\n",
    "# Conversations loop.\n",
    "for conversation in root_train.findall(\"conversation\"):\n",
    "    #total_conversations += 1\n",
    "    authors = defaultdict(list)\n",
    "    all_texts = []\n",
    "\n",
    "    # Messages loop. Keep only those that pass the filters.\n",
    "    for message in conversation.findall(\"message\"):\n",
    "        author_el = message.find(\"author\")\n",
    "        text_el = message.find(\"text\")\n",
    "\n",
    "        if author_el is None or author_el.text is None:\n",
    "            continue\n",
    "        if text_el is None or text_el.text is None:\n",
    "            continue\n",
    "        \n",
    "        author_id = author_el.text.strip()\n",
    "        text = text_el.text.strip()\n",
    "        text = html.unescape(text) # Substitue &amp, &lt;, &gt; etc. with their characters.\n",
    "\n",
    "        # Long sequences of unrecognized characters\n",
    "        if len(text) > 20 and junk_pattern.search(text):\n",
    "            #discarded_messages.append(text) \n",
    "            continue\n",
    "\n",
    "        authors[author_id].append(text)\n",
    "        all_texts.append(text)\n",
    "\n",
    "    # Conversations with only one participant\n",
    "    if len(authors) <= 1:\n",
    "        continue\n",
    "    # Conversations with fewer than six interventions per user\n",
    "    if any(len(msgs) < 6 for msgs in authors.values()):\n",
    "        continue\n",
    "\n",
    "    # If the conversation passes all filters, we keep it.\n",
    "    conversations_clean.append({\n",
    "        \"conversation_id\": conversation.get(\"id\"),\n",
    "        \"authors\": list(authors.keys()),\n",
    "        \"text\": \" \".join(all_texts),\n",
    "        \"messages_by_author\": dict(authors)\n",
    "    })\n",
    "\n",
    "    # Check if any of the authors are predators\n",
    "    #for author_id in authors:\n",
    "        #if author_id in predator_ids_train:\n",
    "            #predators_in_filtered_conversations.add(author_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ac41b",
   "metadata": {},
   "source": [
    "### 2. **Labelling data.**\n",
    "\n",
    "Label all chat conversations as suspicious if they involve at least one predator (SCI task). \n",
    "\n",
    "For these suspicious conversations, separate and label the interventions as predator or victim messages (VFP task).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10faf23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = [] # List to hold conversations with labels\n",
    "interventions = [] # List to hold interventions with labels\n",
    "\n",
    "for convo in conversations_clean:\n",
    "    convo_authors = convo[\"authors\"]\n",
    "    label = 1 if any(author in predator_ids_train for author in convo_authors) else 0\n",
    "\n",
    "    # Conversations labelled\n",
    "    conversations.append({\n",
    "        \"text\": convo[\"text\"],\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "    # If the conversation has predators, label each intervention\n",
    "    if label == 1:\n",
    "        for author, msgs in convo[\"messages_by_author\"].items():\n",
    "            author_label = 1 if author in predator_ids_train else 0\n",
    "            full_intervention = \" \".join(msgs)\n",
    "            # Interventions labelled\n",
    "            interventions.append({\n",
    "                \"intervention\": full_intervention,\n",
    "                \"label\": author_label\n",
    "            })\n",
    "\n",
    "df_conversations = pd.DataFrame(conversations)\n",
    "df_interventions = pd.DataFrame(interventions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d08ac",
   "metadata": {},
   "source": [
    "### 3. **Suspicious Conversations Identification (SCI) stage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992ea40b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: uncorrectable ECC error encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     53\u001b[39m training_args = TrainingArguments(\n\u001b[32m     54\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./bert_out\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     logging_steps=\u001b[32m10\u001b[39m\n\u001b[32m     63\u001b[39m )\n\u001b[32m     65\u001b[39m trainer = Trainer(\n\u001b[32m     66\u001b[39m     model=bert_model,\n\u001b[32m     67\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m     data_collator=DataCollatorWithPadding(tokenizer)\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Inferencia\u001b[39;00m\n\u001b[32m     77\u001b[39m bert_model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   1883\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   1884\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1885\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2216\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2213\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_begin(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2215\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.accumulate(model):\n\u001b[32m-> \u001b[39m\u001b[32m2216\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2219\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2220\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2221\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2222\u001b[39m ):\n\u001b[32m   2223\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2224\u001b[39m     tr_loss += tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3238\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs)\u001b[39m\n\u001b[32m   3235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3237\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3238\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3240\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3241\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3264\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs)\u001b[39m\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3263\u001b[39m     labels = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3264\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3265\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3266\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:184\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t.device != \u001b[38;5;28mself\u001b[39m.src_device_obj:\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    179\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodule must have its parameters and buffers \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mon device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.src_device_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (device_ids[0]) but found one of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthem on device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt.device\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m inputs, module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# for forward function without any inputs, empty list and dict will be created\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# so the module can be executed on one device which is the first one in device_ids\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inputs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:208\u001b[39m, in \u001b[36mDataParallel.scatter\u001b[39m\u001b[34m(self, inputs, kwargs, device_ids)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscatter\u001b[39m(\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    204\u001b[39m     inputs: \u001b[38;5;28mtuple\u001b[39m[Any, ...],\n\u001b[32m    205\u001b[39m     kwargs: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[32m    206\u001b[39m     device_ids: Sequence[Union[\u001b[38;5;28mint\u001b[39m, torch.device]],\n\u001b[32m    207\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py:90\u001b[39m, in \u001b[36mscatter_kwargs\u001b[39m\u001b[34m(inputs, kwargs, target_gpus, dim)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Scatter with support for kwargs dictionary.\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m scattered_inputs = scatter(inputs, target_gpus, dim) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m scattered_kwargs = \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scattered_inputs) < \u001b[38;5;28mlen\u001b[39m(scattered_kwargs):\n\u001b[32m     92\u001b[39m     scattered_inputs.extend(\n\u001b[32m     93\u001b[39m         () \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scattered_kwargs) - \u001b[38;5;28mlen\u001b[39m(scattered_inputs))\n\u001b[32m     94\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py:76\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(inputs, target_gpus, dim)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# After scatter_map is called, a scatter_map cell will exist. This cell\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# has a reference to the actual function scatter_map, which has references\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# to a closure that has a reference to the scatter_map cell (because the\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# fn is recursive). To avoid this reference cycle, we set the function to\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# None, clearing the cell\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     res = \u001b[43mscatter_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     78\u001b[39m     scatter_map = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py:67\u001b[39m, in \u001b[36mscatter.<locals>.scatter_map\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscatter_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [obj \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m target_gpus]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py:63\u001b[39m, in \u001b[36mscatter.<locals>.scatter_map\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(*args) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscatter_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) > \u001b[32m0\u001b[39m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/scatter_gather.py:59\u001b[39m, in \u001b[36mscatter.<locals>.scatter_map\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscatter_map\u001b[39m(obj):\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mScatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_namedtuple(obj):\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtype\u001b[39m(obj)(*args) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*\u001b[38;5;28mmap\u001b[39m(scatter_map, obj))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:104\u001b[39m, in \u001b[36mScatter.forward\u001b[39m\u001b[34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;129;01mand\u001b[39;00m ctx.input_device == -\u001b[32m1\u001b[39m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Perform CPU to GPU copies in a background stream\u001b[39;00m\n\u001b[32m    101\u001b[39m     streams = [\n\u001b[32m    102\u001b[39m         _get_stream(torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, device)) \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m target_gpus\n\u001b[32m    103\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m outputs = \u001b[43mcomm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# Synchronize with the copy stream\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/parallel/comm.py:204\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    203\u001b[39m     devices = [_get_device_index(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m devices]\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m devices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: uncorrectable ECC error encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# === DATOS ===\n",
    "texts = df_conversations[\"text\"]\n",
    "labels = df_conversations[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# === MODELO 1: TF-IDF + SVM ===\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel=\"linear\", probability=True)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "proba_svm = svm.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# === MODELO 2: BGE BASE + MLP ===\n",
    "bge = SentenceTransformer(\"./bge-base-en\", trust_remote_code=True)\n",
    "X_train_bge = bge.encode(X_train.tolist(), normalize_embeddings=True, convert_to_numpy=True)\n",
    "X_test_bge = bge.encode(X_test.tolist(), normalize_embeddings=True, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=200)\n",
    "mlp.fit(X_train_bge, y_train)\n",
    "proba_mlp = mlp.predict_proba(X_test_bge)[:, 1]\n",
    "\n",
    "# === MODELO 3: BERT FINE-TUNED ===\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Cargar desde local\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\"./bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./bert-base-uncased\")\n",
    "\n",
    "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer)\n",
    "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_out\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer)\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Inferencia\n",
    "bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(X_test, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    outputs = bert_model(**inputs)\n",
    "    proba_bert = torch.nn.functional.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "# === ENSAMBLADO FINAL ===\n",
    "# Ajusta pesos si lo deseas\n",
    "final_proba = 0.3 * proba_svm + 0.3 * proba_mlp + 0.4 * proba_bert\n",
    "y_pred = (final_proba > 0.5).astype(int)\n",
    "\n",
    "# === RESULTADOS ===\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901a774",
   "metadata": {},
   "source": [
    "### 4. **Victim From Predator disclosure (VFP) stage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b9e02",
   "metadata": {},
   "source": [
    "### 5. **Evaluate test data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pan12-sexual-predator-identification-groundtruth-problem1.txt\") as f:\n",
    "    predator_ids_test = set(f.read().splitlines())\n",
    "\n",
    "tree_test = ET.parse(\"pan12-sexual-predator-identification-test-corpus-2012-05-17.xml\")\n",
    "root_test = tree_test.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredatorDetectionPipeline:\n",
    "    def __init__(self, conversation_model, author_model):\n",
    "        self.conversation_model = conversation_model\n",
    "        self.author_model = author_model\n",
    "        self.junk_pattern = re.compile(r\"[^a-zA-Z0-9áéíóúÁÉÍÓÚñÑüÜ\\s.,!?*\\'\\\"@():;<>\\/\\-]+\")\n",
    "\n",
    "    def _filter(self, root):\n",
    "        filtered_conversations = []\n",
    "        for conversation in root.findall(\"conversation\"):\n",
    "            authors = defaultdict(list)\n",
    "            all_texts = []\n",
    "\n",
    "            for message in conversation.findall(\"message\"):\n",
    "                author_el = message.find(\"author\")\n",
    "                text_el = message.find(\"text\")\n",
    "\n",
    "                if author_el is None or author_el.text is None:\n",
    "                    continue\n",
    "                if text_el is None or text_el.text is None:\n",
    "                    continue\n",
    "\n",
    "                author_id = author_el.text.strip()\n",
    "                text = html.unescape(text_el.text.strip())\n",
    "\n",
    "                if len(text) > 20 and self.junk_pattern.search(text):\n",
    "                    continue\n",
    "\n",
    "                authors[author_id].append(text)\n",
    "                all_texts.append(text)\n",
    "\n",
    "            if len(authors) <= 1:\n",
    "                continue\n",
    "            if any(len(msgs) < 6 for msgs in authors.values()):\n",
    "                continue\n",
    "\n",
    "            filtered_conversations.append({\n",
    "                \"conversation_id\": conversation.get(\"id\"),\n",
    "                \"authors\": list(authors.keys()),\n",
    "                \"text\": \" \".join(all_texts),\n",
    "                \"messages_by_author\": dict(authors),\n",
    "                \"xml\": conversation\n",
    "            })\n",
    "\n",
    "        return filtered_conversations\n",
    "\n",
    "    def _true_labels(self, conversations, predator_ids):\n",
    "        true_labels = []\n",
    "        for convo in conversations:\n",
    "            convo_authors = convo[\"authors\"]\n",
    "            predator_in_convo = [author for author in convo_authors if author in predator_ids]\n",
    "\n",
    "            if predator_in_convo:\n",
    "                true_labels.append({\n",
    "                    \"conversation_id\": convo[\"conversation_id\"],\n",
    "                    \"suspicious\": True,\n",
    "                    \"predator\": predator_in_convo[0]\n",
    "                })\n",
    "            else:\n",
    "                true_labels.append({\n",
    "                    \"conversation_id\": convo[\"conversation_id\"],\n",
    "                    \"suspicious\": False,\n",
    "                    \"predator\": None\n",
    "                })\n",
    "\n",
    "        return true_labels\n",
    "\n",
    "    def _predict(self, conversation_data):\n",
    "        text = conversation_data[\"text\"]\n",
    "        is_suspicious = self.conversation_model.predict([text])[0]\n",
    "        if not is_suspicious:\n",
    "            return {\n",
    "                \"conversation_id\": conversation_data[\"conversation_id\"],\n",
    "                \"suspicious\": False,\n",
    "                \"predator\": None\n",
    "            }\n",
    "\n",
    "        author_probs = []\n",
    "        for author_id, msgs in conversation_data[\"messages_by_author\"].items():\n",
    "            joined_msgs = \" \".join(msgs)\n",
    "            score = self.author_model.predict_proba([joined_msgs])[0][1]\n",
    "            author_probs.append((author_id, score))\n",
    "\n",
    "        predator_id = max(author_probs, key=lambda x: x[1])[0]\n",
    "\n",
    "        return {\n",
    "            \"conversation_id\": conversation_data[\"conversation_id\"],\n",
    "            \"suspicious\": True,\n",
    "            \"predator\": predator_id\n",
    "        }\n",
    "\n",
    "    def run_pipeline(self, root, predator_ids):\n",
    "        # 1. Filter conversations\n",
    "        conversations = self._filter(root)\n",
    "\n",
    "        # 2. Generate true labels\n",
    "        true_labels = self._true_labels(conversations, predator_ids)\n",
    "\n",
    "        # 3. Predict with the models\n",
    "        predictions = []\n",
    "        for convo in conversations:\n",
    "            resultado = self._predict(convo)\n",
    "            predictions.append(resultado)\n",
    "\n",
    "        # 4. Compare true labels vs. predictions\n",
    "        y_true = [et[\"suspicious\"] for et in true_labels]\n",
    "        y_pred = [pr[\"suspicious\"] for pr in predictions]\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        print(\"Model evaluation:\")\n",
    "        print(f\"Accuracy : {acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall   : {recall:.4f}\")\n",
    "        print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "        return {\n",
    "            \"conversation_metrics\": {\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1\n",
    "            },\n",
    "            \"predictions\": predictions,\n",
    "            \"true_labels\": true_labels\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy Kernel",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
